{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "id": "ceb7cbe1-746d-4b6f-a6e1-6c3f3a7aaa38"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import pickle\n",
        "from torch.utils.data import Dataset\n",
        "import random"
      ],
      "id": "ceb7cbe1-746d-4b6f-a6e1-6c3f3a7aaa38"
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "a03c4cb1-5360-4020-babf-5502ed218c1c"
      },
      "outputs": [],
      "source": [
        "seed = 100\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "id": "a03c4cb1-5360-4020-babf-5502ed218c1c"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hksSNG6jt9A8",
        "outputId": "0ac2198f-66b3-4222-ae8c-5dbcd63ccd54"
      },
      "id": "hksSNG6jt9A8",
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2b33305-ac19-49f5-9aac-a6270fdde835",
        "outputId": "561dc437-f950-44d6-a6c4-723f1ba5d080"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ],
      "source": [
        "device = torch.device('cuda')\n",
        "device"
      ],
      "id": "f2b33305-ac19-49f5-9aac-a6270fdde835"
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "d7be672f-cd6e-44a5-aefc-abcf85f65a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16febc3c-8f5c-4fe2-db78-2ae3d71ec15e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 68., 153.,  41.,  93., 100.,   5., 158., 158.,   3.,  21., 153.,\n",
              "        153.,   2.,  68.,  43.,  12., 180.,   0.,  47.,  78., 114., 114.,\n",
              "         82., 168., 153., 153.,  41.,  93., 100.,   5., 158., 158.,   3.,\n",
              "         21., 153., 153.,   2.,  68.,  43.,  12., 180.,   0.,  47.,  78.,\n",
              "        114., 114.,   0.,   0.,  88.,  88.,   9., 156., 109.,  78.,  30.,\n",
              "        151.,  92., 109., 172.,   5.,  19., 185.,  30.,  78.,  36.,  60.,\n",
              "        185., 157., 144., 144., 114., 180.,  60., 153.,  41.,  93., 100.,\n",
              "          5., 158., 158.,   3.,  21., 153., 153., 126., 136.,  68.,  92.,\n",
              "         76.,  36.,  92., 100.,   5.,  92., 158.,  21.,  80., 168., 100.,\n",
              "        153.,   2.,  80.,  80.,  80.,  80.,  80.,  80.,  -1.]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ],
      "source": [
        "with open('train.pkl', 'rb') as f:\n",
        "    pck_data = pickle.load(f)\n",
        "\n",
        "random.Random(seed).shuffle(pck_data)\n",
        "pck_data[0]"
      ],
      "id": "d7be672f-cd6e-44a5-aefc-abcf85f65a36"
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "f51d7b77-97a7-4c27-9e97-fd843e098784",
        "outputId": "c9bdafff-9cbc-4d9d-965a-765a062fa88b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{3: 441, 1: 478, 0: 1630, 4: 236, 2: 154}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "counts = {}\n",
        "for record in pck_data:\n",
        "    if record[1] in counts:\n",
        "        counts[record[1]] += 1\n",
        "    else:\n",
        "        counts[record[1]] = 1\n",
        "print(counts)\n",
        "\n",
        "plt.bar(list(counts.keys()), list(counts.values()))\n",
        "plt.title(\"rozklad klas\")\n",
        "plt.show()"
      ],
      "id": "f51d7b77-97a7-4c27-9e97-fd843e098784"
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "id": "d72147bf-7f5a-446c-b0b1-b1afbfbc397d"
      },
      "outputs": [],
      "source": [],
      "id": "d72147bf-7f5a-446c-b0b1-b1afbfbc397d"
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3681d42-3d8e-4ca0-ac67-9ba911a44c6c",
        "outputId": "ba1fd644-5e4a-4657-8201-cb7e257b8d66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(191., dtype=torch.float64), tensor(-1., dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ],
      "source": [
        "data = []\n",
        "targets = []\n",
        "max_val = float(\"-inf\")\n",
        "min_val = float(\"inf\")\n",
        "for record in pck_data:\n",
        "    data.append(torch.from_numpy(np.array(record[0])))\n",
        "    targets.append(torch.from_numpy(np.array(record[1])))\n",
        "    max_val = data[-1].max() if data[-1].max() > max_val else max_val\n",
        "    min_val = data[-1].min() if data[-1].min() < min_val else min_val\n",
        "\n",
        "max_val, min_val"
      ],
      "id": "f3681d42-3d8e-4ca0-ac67-9ba911a44c6c"
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {
        "id": "7e979b82-db0e-479f-9d5c-dcff152a3f80"
      },
      "outputs": [],
      "source": [
        "class VariableLenDataset(Dataset):\n",
        "    def __init__(self, in_data, target):\n",
        "        self.data = [(x, y) for x, y in zip(in_data, target)]      \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        in_data, target = self.data[idx]\n",
        "        return in_data, target"
      ],
      "id": "7e979b82-db0e-479f-9d5c-dcff152a3f80"
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "id": "982bf6de-74ab-4a69-abae-b3b61ff6f265"
      },
      "outputs": [],
      "source": [
        "train_indices = int(len(data) * 0.75)\n",
        "data = [( (x - min_val) / (max_val-min_val) - 0.5).float() for x in data]\n",
        "train_set = VariableLenDataset(data[:train_indices], targets[:train_indices])\n",
        "test_set = VariableLenDataset(data[train_indices:], targets[train_indices:])"
      ],
      "id": "982bf6de-74ab-4a69-abae-b3b61ff6f265"
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "id": "fad0e899-4552-48e8-91b2-1b9baaf581f8"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "pad = -1\n",
        "\n",
        "def pad_collate(batch, pad_value=-1):\n",
        "    xx, yy = zip(*batch)\n",
        "    x_lens = [len(x) for x in xx]\n",
        "\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "    return xx_pad, torch.Tensor(yy), torch.Tensor(x_lens)"
      ],
      "id": "fad0e899-4552-48e8-91b2-1b9baaf581f8"
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c0b56c5-1482-459a-a381-277b3751c19d",
        "outputId": "463b73d8-81ff-4190-f33f-22bb2d890536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:563: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0260, -0.0938, -0.1615,  ..., -1.0000, -1.0000, -1.0000])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 40\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=pad_collate, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=False, collate_fn=pad_collate, num_workers=4, pin_memory=True)\n",
        "torch.set_printoptions(profile=\"default\")\n",
        "for a,b,c in test_loader:\n",
        "    print(a[30])\n",
        "    break"
      ],
      "id": "1c0b56c5-1482-459a-a381-277b3751c19d"
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "4b24abb3-c4c9-4231-8268-c968023dad2d"
      },
      "outputs": [],
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers, out_size, batch_size,bidirectional = False):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        if bidirectional:\n",
        "            self.bidirectional = 2\n",
        "        else:\n",
        "            self.bidirectional = 1\n",
        "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, dropout=0.2)\n",
        "        self.fc1 = nn.Linear( (3*hidden_size*self.bidirectional), (3*hidden_size*self.bidirectional) // 2 )\n",
        "        self.bn1 = nn.BatchNorm1d((3*hidden_size*self.bidirectional) // 2)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.d1 = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear((3*hidden_size*self.bidirectional), out_size)\n",
        "        \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "    \n",
        "    def forward(self, x, hidden, lens_x):\n",
        "        curr_b = x.shape[0]\n",
        "        x = torch.transpose(x,0,1)\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        all_outputs = torch.transpose(all_outputs,0,1)\n",
        "        out = torch.zeros((curr_b, 3*self.bidirectional*self.hidden_size), requires_grad=True).to(device)\n",
        "        for i in range(curr_b):\n",
        "          idx1 = lens_x[i]-3\n",
        "          idx2 = lens_x[i]\n",
        "          out[i, :] = all_outputs[i, idx1:idx2, :].flatten()\n",
        "        # x = self.fc1(out)\n",
        "        # x = self.bn1(x)\n",
        "        # x = self.act1(x)\n",
        "        # x = self.d1(x)\n",
        "        x = self.fc2(out)\n",
        "        return x, hidden"
      ],
      "id": "4b24abb3-c4c9-4231-8268-c968023dad2d"
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {
        "id": "671655ef-4357-439c-948f-f349a0a55d5b"
      },
      "outputs": [],
      "source": [
        "\n",
        "#torch.set_printoptions(profile=\"full\")\n",
        "\n",
        "\n",
        "model = LSTMClassifier(1, 32, 2, 5, batch_size, False).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fun = nn.CrossEntropyLoss(weight=torch.Tensor([1, 2, 3, 2, 3]).to(device), reduction='mean')"
      ],
      "id": "671655ef-4357-439c-948f-f349a0a55d5b"
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {
        "id": "dcf786d2-3710-42f4-af7d-14475d8fb504",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "734fa5ab-9bec-4501-d2c2-ff0f84642079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss train: 1.54, loss test: 1.51\n",
            "Epoch: 0, acc train: 0.547, acc test: 0.556\n",
            "Epoch: 1, loss train: 1.53, loss test: 1.31\n",
            "Epoch: 1, acc train: 0.554, acc test: 0.556\n",
            "Epoch: 2, loss train: 1.53, loss test: 1.29\n",
            "Epoch: 2, acc train: 0.555, acc test: 0.556\n",
            "Epoch: 3, loss train: 1.53, loss test: 1.44\n",
            "Epoch: 3, acc train: 0.553, acc test: 0.559\n",
            "Epoch: 4, loss train: 1.52, loss test: 1.39\n",
            "Epoch: 4, acc train: 0.554, acc test: 0.56\n",
            "Epoch: 5, loss train: 1.51, loss test: 1.39\n",
            "Epoch: 5, acc train: 0.553, acc test: 0.566\n",
            "Epoch: 6, loss train: 1.52, loss test: 1.42\n",
            "Epoch: 6, acc train: 0.552, acc test: 0.565\n",
            "Epoch: 7, loss train: 1.52, loss test: 1.38\n",
            "Epoch: 7, acc train: 0.552, acc test: 0.564\n",
            "Epoch: 8, loss train: 1.52, loss test: 1.34\n",
            "Epoch: 8, acc train: 0.553, acc test: 0.563\n",
            "Epoch: 9, loss train: 1.52, loss test: 1.35\n",
            "Epoch: 9, acc train: 0.553, acc test: 0.562\n",
            "Epoch: 10, loss train: 1.52, loss test: 1.32\n",
            "Epoch: 10, acc train: 0.553, acc test: 0.562\n",
            "Epoch: 11, loss train: 1.52, loss test: 1.36\n",
            "Epoch: 11, acc train: 0.553, acc test: 0.561\n",
            "Epoch: 12, loss train: 1.51, loss test: 1.34\n",
            "Epoch: 12, acc train: 0.552, acc test: 0.561\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-271-9a025cb76d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlosses_epoch_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import sys\n",
        "model.train()\n",
        "\n",
        "losses_train = []\n",
        "losses_epoch_train = []\n",
        "losses_test = []\n",
        "losses_epoch_test = []\n",
        "\n",
        "acc_train = []\n",
        "acc_epoch_train = []\n",
        "acc_test = []\n",
        "acc_epoch_test = []\n",
        "\n",
        "\n",
        "for epoch in range(250):\n",
        "    model.train()\n",
        "    for x, targets, lens in train_loader:\n",
        "        targets = targets.long()\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        lens = lens.long().to(device)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device)\n",
        "        preds, _ = model(x, (hidden,state), lens)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fun(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses_epoch_train.append(loss.item())\n",
        "        acc = (preds.argmax(dim=1) == targets).sum() / preds.shape[0]\n",
        "        acc_epoch_train.append(acc.cpu())\n",
        "    losses_train.append(np.mean(losses_epoch_train))\n",
        "    acc_train.append(np.mean(acc_epoch_train))\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, targets, lens in test_loader:\n",
        "            targets = targets.long()\n",
        "            x = x.to(device).unsqueeze(2)\n",
        "            lens = lens.long().to(device)\n",
        "            targets = targets.to(device)\n",
        "            hidden, state = model.init_hidden(x.size(0))\n",
        "            hidden, state = hidden.to(device), state.to(device)\n",
        "            preds, _ = model(x, (hidden,state), lens)\n",
        "            losses_epoch_test.append(loss.item())\n",
        "            acc = (preds.argmax(dim=1) == targets).sum() / preds.shape[0]\n",
        "            acc_epoch_test.append(acc.cpu())\n",
        "    losses_test.append(np.mean(losses_epoch_test))\n",
        "    acc_test.append(np.mean(acc_epoch_test))\n",
        "    print(f\"Epoch: {epoch}, loss train: {losses_train[-1]:.3}, loss test: {losses_test[-1]:.3}\")\n",
        "    print(f\"Epoch: {epoch}, acc train: {acc_train[-1]:.3}, acc test: {acc_test[-1]:.3}\")"
      ],
      "id": "dcf786d2-3710-42f4-af7d-14475d8fb504"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ca78a89f-825d-48ca-a4d9-fcf6c6a78a2e"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.grid(True)\n",
        "plt.plot(losses_train)\n",
        "plt.plot(losses_test)\n",
        "plt.title(\"Loss\")\n",
        "plt.legend([\"train\", \"valid\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.grid(True)\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(acc_train)\n",
        "plt.plot(acc_test)\n",
        "plt.legend([\"train\", \"valid\"])\n",
        "print('Finished Training')"
      ],
      "id": "ca78a89f-825d-48ca-a4d9-fcf6c6a78a2e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf1ed33e-a9e8-4c3f-b2ba-640144a9b321"
      },
      "outputs": [],
      "source": [
        "correct_preds = [0 for _ in range(5)]\n",
        "total_preds = [0 for _ in range(5)]\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, targets, lens in test_loader:\n",
        "        targets = targets.long()\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        lens = lens.long().to(device)\n",
        "        targets = targets.to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device)\n",
        "        preds, _ = model(x, (hidden,state), lens)\n",
        "        losses_epoch_test.append(loss.item())\n",
        "        acc = (preds.argmax(dim=1) == targets).sum() / preds.shape[0]\n",
        "        acc_epoch_test.append(acc.cpu())\n",
        "\n",
        "\n",
        "        _, max_preds = torch.max(preds, 1)\n",
        "        for label, prediction in zip(targets, max_preds):\n",
        "          label = label.item()\n",
        "          if label == prediction:\n",
        "              correct_preds[label] += 1\n",
        "          total_preds[label] += 1\n",
        "\n",
        "\n",
        "print(f\"Acc: {np.mean(acc_epoch_test)}\")\n",
        "\n",
        "class_accs = []\n",
        "for i, correct_count in enumerate(correct_preds):\n",
        "    accuracy = 100 * float(correct_count) / total_preds[i]\n",
        "    print(f\"Accuracy for class {i} is: {accuracy} %\")\n",
        "    class_accs.append(accuracy)\n",
        "\n",
        "print(f\"Avg class acc: {np.array(class_accs).mean()}\")"
      ],
      "id": "cf1ed33e-a9e8-4c3f-b2ba-640144a9b321"
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model.state_dict(), 'model42')"
      ],
      "metadata": {
        "id": "I3jzACfKvAuW"
      },
      "id": "I3jzACfKvAuW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predykcje dla zbioru testowego\n",
        "predictions = []\n",
        "composers = {0: 'bach', 1: 'beethoven', 2: 'debussy', 3: 'scarlatti', 4: 'victoria'}\n",
        "with open('test_no_target.pkl', 'rb') as f:\n",
        "    pck_data_test = pickle.load(f)\n",
        "print(len(pck_data_test))\n",
        "data_test = []\n",
        "targets = []\n",
        "for record in pck_data_test:\n",
        "    data_test.append(torch.from_numpy(np.array(record)))\n",
        "    targets.append(torch.Tensor([-10]))\n",
        "\n",
        "data_test = [( (x - min_val) / (max_val-min_val) - 0.5).float() for x in data_test]\n",
        "test_set = VariableLenDataset(data_test, targets)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, collate_fn=pad_collate)\n",
        "\n",
        "for a,b,c in test_loader:\n",
        "  print(a[0])\n",
        "  break\n",
        "predictions = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, targets, lens in test_loader:\n",
        "        x = x.to(device).unsqueeze(2)\n",
        "        lens = lens.long().to(device)\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device)\n",
        "        preds, _ = model(x, (hidden,state), lens)\n",
        "        preds = preds.argmax(dim=1)\n",
        "        predictions.append(preds.cpu().detach().numpy())\n",
        "\n",
        "predictions = np.concatenate(predictions, axis=0)\n"
      ],
      "metadata": {
        "id": "jI9xktnavGtA"
      },
      "id": "jI9xktnavGtA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(predictions)"
      ],
      "metadata": {
        "id": "iGJcJ2XH_sYS"
      },
      "id": "iGJcJ2XH_sYS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"predictions.csv\", index=False, header=False)"
      ],
      "metadata": {
        "id": "yihnkREX_sRu"
      },
      "id": "yihnkREX_sRu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYsy_HLR_zWS"
      },
      "id": "EYsy_HLR_zWS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}